{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "234afff3",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Cell Annotation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb956cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbe6178-ea4d-478a-80a8-65ffaa4c1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GPU_NUMBER = [0,1,2]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67751636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vsphhome/xwx/Geneformer/examples\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb23bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: transformers==4.28.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (4.28.0)\n",
      "Requirement already satisfied: filelock in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from transformers==4.28.0) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->transformers==4.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->transformers==4.28.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->transformers==4.28.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->transformers==4.28.0) (2023.11.17)\n",
      "Requirement already satisfied: accelerate in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (0.27.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from accelerate) (0.4.0)\n",
      "Requirement already satisfied: filelock in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "Successfully installed accelerate-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install transformers==4.28.0\n",
    "!pip install --upgrade accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9885d9f-00ac-4c84-b6a3-b7b648a90f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import pickle\n",
    "import subprocess\n",
    "import seaborn as sns; sns.set()\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from geneformer import DataCollatorForCellClassification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68bd3b98-5409-4105-b7af-f1ff64ea6a72",
   "metadata": {},
   "source": [
    "## Prepare training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5735f1b7-7595-4a02-be17-2c5b970ad81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cell type dataset (includes all tissues)\n",
    "train_dataset=load_from_disk(\"/vsphhome/xwx/Geneformer/token_data/MMD_snRNA.dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836285af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'label', 'length'],\n",
      "    num_rows: 78886\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2048,\n",
       " 1274,\n",
       " 969,\n",
       " 1666,\n",
       " 1029,\n",
       " 305,\n",
       " 359,\n",
       " 2048,\n",
       " 1008,\n",
       " 303,\n",
       " 354,\n",
       " 282,\n",
       " 409,\n",
       " 1478,\n",
       " 400,\n",
       " 369,\n",
       " 1850,\n",
       " 294,\n",
       " 2048,\n",
       " 1100,\n",
       " 1748,\n",
       " 2048,\n",
       " 337,\n",
       " 314,\n",
       " 1244,\n",
       " 991,\n",
       " 408,\n",
       " 345,\n",
       " 298,\n",
       " 2022,\n",
       " 2048,\n",
       " 2048,\n",
       " 1631,\n",
       " 331,\n",
       " 1085,\n",
       " 419,\n",
       " 983,\n",
       " 322,\n",
       " 1413,\n",
       " 1206,\n",
       " 2046,\n",
       " 2048,\n",
       " 1291,\n",
       " 1414,\n",
       " 1608,\n",
       " 311,\n",
       " 1199,\n",
       " 1109,\n",
       " 1908,\n",
       " 288,\n",
       " 323,\n",
       " 1075,\n",
       " 347,\n",
       " 328,\n",
       " 2048,\n",
       " 465,\n",
       " 406,\n",
       " 1063,\n",
       " 2048,\n",
       " 2048,\n",
       " 1665,\n",
       " 357,\n",
       " 428,\n",
       " 849,\n",
       " 971,\n",
       " 1783,\n",
       " 2048,\n",
       " 325,\n",
       " 288,\n",
       " 312,\n",
       " 366,\n",
       " 2048,\n",
       " 415,\n",
       " 1314,\n",
       " 419,\n",
       " 1064,\n",
       " 383,\n",
       " 2048,\n",
       " 411,\n",
       " 1352,\n",
       " 1094,\n",
       " 1069,\n",
       " 940,\n",
       " 1023,\n",
       " 1274,\n",
       " 1457,\n",
       " 363,\n",
       " 307,\n",
       " 318,\n",
       " 1062,\n",
       " 1170,\n",
       " 302,\n",
       " 1545,\n",
       " 1437,\n",
       " 401,\n",
       " 299,\n",
       " 437,\n",
       " 2048,\n",
       " 905,\n",
       " 1467,\n",
       " 263,\n",
       " 309,\n",
       " 1132,\n",
       " 394,\n",
       " 398,\n",
       " 347,\n",
       " 325,\n",
       " 1223,\n",
       " 1015,\n",
       " 411,\n",
       " 2048,\n",
       " 291,\n",
       " 323,\n",
       " 2048,\n",
       " 2048,\n",
       " 1245,\n",
       " 2048,\n",
       " 2048,\n",
       " 396,\n",
       " 2048,\n",
       " 365,\n",
       " 332,\n",
       " 347,\n",
       " 411,\n",
       " 289,\n",
       " 1022,\n",
       " 2042,\n",
       " 295,\n",
       " 2048,\n",
       " 282,\n",
       " 1292,\n",
       " 325,\n",
       " 412,\n",
       " 2003,\n",
       " 1577,\n",
       " 316,\n",
       " 337,\n",
       " 1297,\n",
       " 325,\n",
       " 2048,\n",
       " 300,\n",
       " 1889,\n",
       " 373,\n",
       " 1632,\n",
       " 298,\n",
       " 2048,\n",
       " 1365,\n",
       " 1227,\n",
       " 1015,\n",
       " 2048,\n",
       " 1654,\n",
       " 369,\n",
       " 312,\n",
       " 1935,\n",
       " 354,\n",
       " 2048,\n",
       " 1927,\n",
       " 2048,\n",
       " 2048,\n",
       " 2048,\n",
       " 453,\n",
       " 1208,\n",
       " 2048,\n",
       " 2048,\n",
       " 274,\n",
       " 1742,\n",
       " 2048,\n",
       " 1755,\n",
       " 2048,\n",
       " 369,\n",
       " 342,\n",
       " 1371,\n",
       " 1781,\n",
       " 1016,\n",
       " 1690,\n",
       " 308,\n",
       " 408,\n",
       " 317,\n",
       " 1707,\n",
       " 2048,\n",
       " 328,\n",
       " 2048,\n",
       " 1856,\n",
       " 353,\n",
       " 1283,\n",
       " 431,\n",
       " 1512,\n",
       " 1040,\n",
       " 317,\n",
       " 437,\n",
       " 349,\n",
       " 2048,\n",
       " 282,\n",
       " 1314,\n",
       " 1125,\n",
       " 1247,\n",
       " 1439,\n",
       " 352,\n",
       " 901,\n",
       " 365,\n",
       " 1715,\n",
       " 431,\n",
       " 431,\n",
       " 1252,\n",
       " 322,\n",
       " 290,\n",
       " 371,\n",
       " 2048,\n",
       " 306,\n",
       " 2048,\n",
       " 942,\n",
       " 440,\n",
       " 362,\n",
       " 357,\n",
       " 424,\n",
       " 930,\n",
       " 1031,\n",
       " 1435,\n",
       " 470,\n",
       " 285,\n",
       " 469,\n",
       " 309,\n",
       " 438,\n",
       " 442,\n",
       " 2048,\n",
       " 2048,\n",
       " 2048,\n",
       " 1204,\n",
       " 353,\n",
       " 391,\n",
       " 940,\n",
       " 417,\n",
       " 2048,\n",
       " 327,\n",
       " 426,\n",
       " 1910,\n",
       " 898,\n",
       " 2048,\n",
       " 1069,\n",
       " 2048,\n",
       " 2048,\n",
       " 1007,\n",
       " 329,\n",
       " 960,\n",
       " 390,\n",
       " 1440,\n",
       " 359,\n",
       " 330,\n",
       " 1027,\n",
       " 1811,\n",
       " 943,\n",
       " 376,\n",
       " 307,\n",
       " 1493,\n",
       " 418,\n",
       " 1024,\n",
       " 444,\n",
       " 306,\n",
       " 1241,\n",
       " 327,\n",
       " 413,\n",
       " 1213,\n",
       " 455,\n",
       " 449,\n",
       " 354,\n",
       " 302,\n",
       " 1290,\n",
       " 1438,\n",
       " 2048,\n",
       " 407,\n",
       " 347,\n",
       " 2048,\n",
       " 2048,\n",
       " 317,\n",
       " 284,\n",
       " 1094,\n",
       " 297,\n",
       " 444,\n",
       " 2048,\n",
       " 2017,\n",
       " 1772,\n",
       " 1005,\n",
       " 1227,\n",
       " 2048,\n",
       " 2048,\n",
       " 1369,\n",
       " 419,\n",
       " 2048,\n",
       " 319,\n",
       " 437,\n",
       " 1046,\n",
       " 368,\n",
       " 359,\n",
       " 360,\n",
       " 1500,\n",
       " 1338,\n",
       " 276,\n",
       " 389,\n",
       " 374,\n",
       " 313,\n",
       " 2048,\n",
       " 2048,\n",
       " 2048,\n",
       " 437,\n",
       " 1852,\n",
       " 287,\n",
       " 454,\n",
       " 400,\n",
       " 335,\n",
       " 419,\n",
       " 437,\n",
       " 346,\n",
       " 1417,\n",
       " 1991,\n",
       " 333,\n",
       " 1360,\n",
       " 395,\n",
       " 294,\n",
       " 393,\n",
       " 1035,\n",
       " 2048,\n",
       " 293,\n",
       " 484,\n",
       " 438,\n",
       " 340,\n",
       " 1644,\n",
       " 1376,\n",
       " 374,\n",
       " 1523,\n",
       " 310,\n",
       " 1235,\n",
       " 436,\n",
       " 1141,\n",
       " 1414,\n",
       " 2048,\n",
       " 331,\n",
       " 1374,\n",
       " 2048,\n",
       " 2048,\n",
       " 313,\n",
       " 411,\n",
       " 1451,\n",
       " 1392,\n",
       " 1885,\n",
       " 1790,\n",
       " 1018,\n",
       " 395,\n",
       " 933,\n",
       " 2048,\n",
       " 1896,\n",
       " 401,\n",
       " 1602,\n",
       " 318,\n",
       " 2048,\n",
       " 2048,\n",
       " 2048,\n",
       " 269,\n",
       " 428,\n",
       " 416,\n",
       " 1248,\n",
       " 372,\n",
       " 288,\n",
       " 1124,\n",
       " 1717,\n",
       " 2048,\n",
       " 402,\n",
       " 351,\n",
       " 1639,\n",
       " 1998,\n",
       " 1325,\n",
       " 1614,\n",
       " 934,\n",
       " 1731,\n",
       " 1715,\n",
       " 1191,\n",
       " 1990,\n",
       " 357,\n",
       " 2048,\n",
       " 1493,\n",
       " 1245,\n",
       " 2048,\n",
       " 317,\n",
       " 2048,\n",
       " 394,\n",
       " 372,\n",
       " 344,\n",
       " 283,\n",
       " 1500,\n",
       " 1115,\n",
       " 1606,\n",
       " 389,\n",
       " 323,\n",
       " 1869,\n",
       " 2048,\n",
       " 287,\n",
       " 1074,\n",
       " 409,\n",
       " 2048,\n",
       " 343,\n",
       " 345,\n",
       " 2048,\n",
       " 1086,\n",
       " 2048,\n",
       " 1422,\n",
       " 389,\n",
       " 399,\n",
       " 342,\n",
       " 354,\n",
       " 1745,\n",
       " 1205,\n",
       " 313,\n",
       " 1152,\n",
       " 2048,\n",
       " 1274,\n",
       " 450,\n",
       " 415,\n",
       " 1893,\n",
       " 1203,\n",
       " 1466,\n",
       " 307,\n",
       " 436,\n",
       " 363,\n",
       " 287,\n",
       " 290,\n",
       " 313,\n",
       " 414,\n",
       " 2048,\n",
       " 951,\n",
       " 1181,\n",
       " 432,\n",
       " 398,\n",
       " 1312,\n",
       " 2048,\n",
       " 2048,\n",
       " 1786,\n",
       " 372,\n",
       " 1128,\n",
       " 1791,\n",
       " 1428,\n",
       " 356,\n",
       " 1233,\n",
       " 1489,\n",
       " 938,\n",
       " 349,\n",
       " 913,\n",
       " 389,\n",
       " 306,\n",
       " 452,\n",
       " 1436,\n",
       " 2048,\n",
       " 2048,\n",
       " 291,\n",
       " 295,\n",
       " 292,\n",
       " 289,\n",
       " 301,\n",
       " 312,\n",
       " 2048,\n",
       " 2048,\n",
       " 2048,\n",
       " 1187,\n",
       " 2048,\n",
       " 1065,\n",
       " 2048,\n",
       " 1144,\n",
       " 341,\n",
       " 1029,\n",
       " 292,\n",
       " 355,\n",
       " 374,\n",
       " 358,\n",
       " 2012,\n",
       " 350,\n",
       " 2048,\n",
       " 381,\n",
       " 417,\n",
       " 2048,\n",
       " 1948,\n",
       " 1348,\n",
       " 1425,\n",
       " 328,\n",
       " 397,\n",
       " 1798,\n",
       " 316,\n",
       " 980,\n",
       " 286,\n",
       " 363,\n",
       " 978,\n",
       " 2048,\n",
       " 1186,\n",
       " 316,\n",
       " 328,\n",
       " 1157,\n",
       " 1407,\n",
       " 394,\n",
       " 2048,\n",
       " 1195,\n",
       " 475,\n",
       " 1481,\n",
       " 1103,\n",
       " 1629,\n",
       " 336,\n",
       " 1323,\n",
       " 415,\n",
       " 2048,\n",
       " 2048,\n",
       " 1777,\n",
       " 1493,\n",
       " 1770,\n",
       " 317,\n",
       " 1328,\n",
       " 1566,\n",
       " 441,\n",
       " 396,\n",
       " 1843,\n",
       " 1755,\n",
       " 1518,\n",
       " 2048,\n",
       " 1960,\n",
       " 374,\n",
       " 383,\n",
       " 1228,\n",
       " 1390,\n",
       " 367,\n",
       " 300,\n",
       " 2048,\n",
       " 314,\n",
       " 369,\n",
       " 326,\n",
       " 1302,\n",
       " 340,\n",
       " 289,\n",
       " 1909,\n",
       " 289,\n",
       " 1613,\n",
       " 1451,\n",
       " 383,\n",
       " 1835,\n",
       " 286,\n",
       " 1992,\n",
       " 424,\n",
       " 285,\n",
       " 1620,\n",
       " 1227,\n",
       " 323,\n",
       " 1463,\n",
       " 2048,\n",
       " 1006,\n",
       " 1247,\n",
       " 288,\n",
       " 1652,\n",
       " 1348,\n",
       " 1861,\n",
       " 397,\n",
       " 281,\n",
       " 337,\n",
       " 314,\n",
       " 1667,\n",
       " 304,\n",
       " 2048,\n",
       " 1302,\n",
       " 2048,\n",
       " 297,\n",
       " 1172,\n",
       " 1814,\n",
       " 376,\n",
       " 2048,\n",
       " 313,\n",
       " 1740,\n",
       " 317,\n",
       " 2048,\n",
       " 1330,\n",
       " 995,\n",
       " 446,\n",
       " 1165,\n",
       " 1090,\n",
       " 409,\n",
       " 997,\n",
       " 309,\n",
       " 410,\n",
       " 1576,\n",
       " 1185,\n",
       " 316,\n",
       " 340,\n",
       " 341,\n",
       " 1430,\n",
       " 2048,\n",
       " 1394,\n",
       " 2048,\n",
       " 336,\n",
       " 313,\n",
       " 1785,\n",
       " 1694,\n",
       " 1529,\n",
       " 1882,\n",
       " 438,\n",
       " 388,\n",
       " 2048,\n",
       " 1436,\n",
       " 1290,\n",
       " 2048,\n",
       " 344,\n",
       " 1097,\n",
       " 1198,\n",
       " 2048,\n",
       " 1347,\n",
       " 2048,\n",
       " 1638,\n",
       " 426,\n",
       " 302,\n",
       " 2048,\n",
       " 1731,\n",
       " 2044,\n",
       " 1391,\n",
       " 1450,\n",
       " 364,\n",
       " 413,\n",
       " 306,\n",
       " 285,\n",
       " 332,\n",
       " 297,\n",
       " 278,\n",
       " 1736,\n",
       " 1653,\n",
       " 358,\n",
       " 1525,\n",
       " 2048,\n",
       " 1087,\n",
       " 326,\n",
       " 1190,\n",
       " 2048,\n",
       " 974,\n",
       " 308,\n",
       " 451,\n",
       " 431,\n",
       " 404,\n",
       " 409,\n",
       " 1446,\n",
       " 1850,\n",
       " 1296,\n",
       " 1188,\n",
       " 1922,\n",
       " 406,\n",
       " 2048,\n",
       " 1617,\n",
       " 307,\n",
       " 1173,\n",
       " 425,\n",
       " 1018,\n",
       " 1164,\n",
       " 410,\n",
       " 398,\n",
       " 308,\n",
       " 1055,\n",
       " 338,\n",
       " 278,\n",
       " 377,\n",
       " 350,\n",
       " 446,\n",
       " 419,\n",
       " 1511,\n",
       " 417,\n",
       " 1174,\n",
       " 361,\n",
       " 2048,\n",
       " 1196,\n",
       " 1669,\n",
       " 461,\n",
       " 2048,\n",
       " 332,\n",
       " 331,\n",
       " 1611,\n",
       " 1576,\n",
       " 1751,\n",
       " 904,\n",
       " 319,\n",
       " 1175,\n",
       " 2048,\n",
       " 1145,\n",
       " 355,\n",
       " 1052,\n",
       " 326,\n",
       " 1128,\n",
       " 1126,\n",
       " 289,\n",
       " 878,\n",
       " 1478,\n",
       " 413,\n",
       " 309,\n",
       " 964,\n",
       " 1313,\n",
       " 334,\n",
       " 834,\n",
       " 1088,\n",
       " 2048,\n",
       " 358,\n",
       " 331,\n",
       " 384,\n",
       " 2048,\n",
       " 1768,\n",
       " 339,\n",
       " 325,\n",
       " 2048,\n",
       " 2048,\n",
       " 1433,\n",
       " 2048,\n",
       " 377,\n",
       " 1762,\n",
       " 347,\n",
       " 269,\n",
       " 1133,\n",
       " 407,\n",
       " 1036,\n",
       " 447,\n",
       " 367,\n",
       " 1677,\n",
       " 331,\n",
       " 379,\n",
       " 362,\n",
       " 321,\n",
       " 303,\n",
       " 348,\n",
       " 300,\n",
       " 1810,\n",
       " 2048,\n",
       " 1888,\n",
       " 2048,\n",
       " 393,\n",
       " 2048,\n",
       " 339,\n",
       " 343,\n",
       " 1229,\n",
       " 361,\n",
       " 1518,\n",
       " 379,\n",
       " 312,\n",
       " 365,\n",
       " 1836,\n",
       " 357,\n",
       " 313,\n",
       " 311,\n",
       " 450,\n",
       " 2048,\n",
       " 331,\n",
       " 441,\n",
       " 2048,\n",
       " 1323,\n",
       " 301,\n",
       " 441,\n",
       " 2048,\n",
       " 374,\n",
       " 353,\n",
       " 1070,\n",
       " 1325,\n",
       " 1036,\n",
       " 349,\n",
       " 303,\n",
       " 310,\n",
       " 1721,\n",
       " 346,\n",
       " 1128,\n",
       " 2048,\n",
       " 394,\n",
       " 351,\n",
       " 1167,\n",
       " 320,\n",
       " 337,\n",
       " 1211,\n",
       " 393,\n",
       " 1718,\n",
       " 289,\n",
       " 1441,\n",
       " 938,\n",
       " 2048,\n",
       " 363,\n",
       " 2048,\n",
       " 325,\n",
       " 364,\n",
       " 415,\n",
       " 2048,\n",
       " 347,\n",
       " 306,\n",
       " 362,\n",
       " 1685,\n",
       " 282,\n",
       " 1071,\n",
       " 2048,\n",
       " 322,\n",
       " 321,\n",
       " 427,\n",
       " 1608,\n",
       " 336,\n",
       " 305,\n",
       " 358,\n",
       " 1484,\n",
       " 1449,\n",
       " 1697,\n",
       " 407,\n",
       " 421,\n",
       " 314,\n",
       " 2048,\n",
       " 395,\n",
       " 1355,\n",
       " 1602,\n",
       " 343,\n",
       " 1510,\n",
       " 1732,\n",
       " 1073,\n",
       " 395,\n",
       " 1739,\n",
       " 374,\n",
       " 913,\n",
       " 335,\n",
       " 315,\n",
       " 306,\n",
       " 462,\n",
       " 427,\n",
       " 407,\n",
       " 467,\n",
       " 457,\n",
       " 1215,\n",
       " 1328,\n",
       " 414,\n",
       " 1014,\n",
       " 1461,\n",
       " 388,\n",
       " 379,\n",
       " 1239,\n",
       " 304,\n",
       " 1454,\n",
       " 2048,\n",
       " 1699,\n",
       " 1385,\n",
       " 1173,\n",
       " 307,\n",
       " 1039,\n",
       " 378,\n",
       " 1234,\n",
       " 368,\n",
       " 393,\n",
       " 348,\n",
       " 1374,\n",
       " 380,\n",
       " 1043,\n",
       " 448,\n",
       " 1179,\n",
       " 1766,\n",
       " 2048,\n",
       " 2048,\n",
       " 917,\n",
       " 319,\n",
       " 2048,\n",
       " 1788,\n",
       " 919,\n",
       " 389,\n",
       " 363,\n",
       " 325,\n",
       " 450,\n",
       " 2048,\n",
       " 338,\n",
       " 347,\n",
       " 1539,\n",
       " 1725,\n",
       " 362,\n",
       " 262,\n",
       " 948,\n",
       " 1486,\n",
       " 2048,\n",
       " 434,\n",
       " 2048,\n",
       " 349,\n",
       " 274,\n",
       " 1619,\n",
       " 332,\n",
       " 423,\n",
       " 2019,\n",
       " 1279,\n",
       " 2048,\n",
       " 1620,\n",
       " 2048,\n",
       " 1605,\n",
       " 2048,\n",
       " 467,\n",
       " 918,\n",
       " 2048,\n",
       " 2048,\n",
       " 294,\n",
       " 322,\n",
       " 1748,\n",
       " 1365,\n",
       " 1852,\n",
       " 1011,\n",
       " 358,\n",
       " 336,\n",
       " 396,\n",
       " 403,\n",
       " 1607,\n",
       " 321,\n",
       " 388,\n",
       " 2048,\n",
       " 919,\n",
       " 385,\n",
       " 1286,\n",
       " 2048,\n",
       " 912,\n",
       " 2048,\n",
       " 2048,\n",
       " 344,\n",
       " 348,\n",
       " 307,\n",
       " 2048,\n",
       " 391,\n",
       " 1553,\n",
       " 1216,\n",
       " 1282,\n",
       " 285,\n",
       " 1657,\n",
       " 342,\n",
       " 377,\n",
       " 425,\n",
       " 396,\n",
       " 291,\n",
       " 965,\n",
       " 316,\n",
       " 994,\n",
       " 1875,\n",
       " 1309,\n",
       " 408,\n",
       " 986,\n",
       " 2048,\n",
       " 326,\n",
       " 1176,\n",
       " 1174,\n",
       " 348,\n",
       " 1080,\n",
       " 395,\n",
       " 389,\n",
       " 1514,\n",
       " 2048,\n",
       " 1311,\n",
       " 1506,\n",
       " 1891,\n",
       " 376,\n",
       " 389,\n",
       " 2048,\n",
       " 330,\n",
       " 2048,\n",
       " 382,\n",
       " 1034,\n",
       " 1834,\n",
       " 2048,\n",
       " 328,\n",
       " 398,\n",
       " 282,\n",
       " 299,\n",
       " 370,\n",
       " 1287,\n",
       " 288,\n",
       " 1946,\n",
       " 1294,\n",
       " 964,\n",
       " 375,\n",
       " 1510,\n",
       " 1030,\n",
       " 1657,\n",
       " 381,\n",
       " 440,\n",
       " 2048,\n",
       " 1075,\n",
       " 1058,\n",
       " 382,\n",
       " 898,\n",
       " 440,\n",
       " 478,\n",
       " 338,\n",
       " 1352,\n",
       " 396,\n",
       " 1141,\n",
       " 1241,\n",
       " 377,\n",
       " 2048,\n",
       " 336,\n",
       " 1461,\n",
       " 1983,\n",
       " 1019,\n",
       " 1040,\n",
       " 381,\n",
       " 1778,\n",
       " 434,\n",
       " 2048,\n",
       " 333,\n",
       " 296,\n",
       " 325,\n",
       " 405,\n",
       " 2048,\n",
       " 325,\n",
       " 321,\n",
       " 1541,\n",
       " 469,\n",
       " 348,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "import pandas as pd\n",
    "# input_ids represent rank encodings\n",
    "pd.DataFrame(train_dataset)\n",
    "train_dataset['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4297a02-4c4c-434c-ae55-3387a0b239b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target name: ['Control', 'Suicide']\n",
      "{'Control': 0, 'Suicide': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9768633e6b04e0b8c9b596ef364c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/78886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_list = []\n",
    "evalset_list = []\n",
    "target_dict_list = []\n",
    "\n",
    "train_dataset_shuffled = train_dataset.shuffle(seed=42)\n",
    "\n",
    "\n",
    "\n",
    "# create dictionary of cell types : label ids \n",
    "target_names = list(Counter(train_dataset_shuffled[\"label\"]).keys())\n",
    "print(f\"target name: {target_names}\")\n",
    "\n",
    "target_name_id_dict = dict(zip(target_names,[i for i in range(len(target_names))]))\n",
    "target_dict_list += [target_name_id_dict]\n",
    "print(target_name_id_dict)\n",
    "\n",
    "# change labels to numerical ids\n",
    "def classes_to_ids(example):\n",
    "    example[\"label\"] = target_name_id_dict[example[\"label\"]]\n",
    "    return example\n",
    "labeled_trainset = train_dataset_shuffled.map(classes_to_ids, num_proc=16)\n",
    "\n",
    "# create 80/20 train/eval splits\n",
    "labeled_train_split = labeled_trainset.select([i for i in range(0,round(len(labeled_trainset)*0.8))])\n",
    "labeled_eval_split = labeled_trainset.select([i for i in range(round(len(labeled_trainset)*0.8),len(labeled_trainset))])\n",
    "\n",
    "dataset_list += [labeled_train_split]\n",
    "evalset_list += [labeled_eval_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e20521-597a-4c54-897b-c4d42ea622c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dict=dataset_list\n",
    "\n",
    "evalset_dict=evalset_list\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10eb110d-ba43-4efc-bc43-1815d6912647",
   "metadata": {},
   "source": [
    "## Fine-Tune With Cell Classification Learning Objective and Quantify Predictive Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7b1cfb-f5cb-460e-ae77-769522ece054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy and macro f1 using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "      'macro_f1': macro_f1\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beaab7a4-cc13-4e8f-b137-ed18ff7b633c",
   "metadata": {},
   "source": [
    "### Please note that, as usual with deep learning models, we **highly** recommend tuning learning hyperparameters for all fine-tuning applications as this can significantly improve model performance. Example hyperparameters are defined below, but please see the \"hyperparam_optimiz_for_disease_classifier\" script for an example of how to tune hyperparameters for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d24e1ab7-0131-44bd-b458-1ce5ba31853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "# max input size\n",
    "max_input_size = 2048  # 2048 2 ** 11\n",
    " \n",
    "# set training hyperparameters\n",
    "# max learning rate\n",
    "max_lr = 5e-5\n",
    "# how many pretrained layers to freeze\n",
    "freeze_layers = 3\n",
    "# number gpus\n",
    "num_gpus = 3 #4\n",
    "# number cpu cores\n",
    "num_proc = 16\n",
    "# batch size for training and eval\n",
    "geneformer_batch_size = 12 #12\n",
    "# learning schedule\n",
    "lr_schedule_fn = \"linear\"\n",
    "# warmup steps\n",
    "warmup_steps = 500\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "# optimizer\n",
    "optimizer = \"adamw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6701818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for organ in organ_list:\n",
    "organ_trainset = trainset_dict\n",
    "organ_evalset = evalset_dict\n",
    "# organ_label_dict = traintargetdict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5b1209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'label', 'length'],\n",
       "    num_rows: 63109\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organ_trainset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05164c24-5fbf-4372-b26c-a43f3777a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /vsphhome/xwx/Geneformer were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /vsphhome/xwx/Geneformer and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "mkdir: cannot create directory ‘/vsphhome/xwx/Geneformer/models/240329_geneformer_DepressionClassifier_L2048_B12_LR5e-05_LSlinear_WU500_E10_Oadamw_F3/’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(25426, 256, padding_idx=0)\n",
      "      (position_embeddings): Embedding(2048, 256)\n",
      "      (token_type_embeddings): Embedding(2, 256)\n",
      "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.02, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.02, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.02, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): ReLU()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.02, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.02, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='17540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  140/17540 00:28 < 58:50, 4.93 it/s, Epoch 0.08/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/vsphhome/xwx/anaconda3/envs/geneenv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='439' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10/439 00:01 < 00:48, 8.84 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for organ in organ_list:\n",
    "organ_trainset = trainset_dict[0]\n",
    "organ_evalset = evalset_dict[0]\n",
    "# organ_label_dict = traintargetdict_dict\n",
    "\n",
    "# set logging steps\n",
    "logging_steps = round(len(organ_trainset)/geneformer_batch_size/10)\n",
    "\n",
    "# reload pretrained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"/vsphhome/xwx/Geneformer\", \n",
    "                                                    num_labels=2,\n",
    "                                                    output_attentions = False,\n",
    "                                                    #from_tf=True,\n",
    "                                                    output_hidden_states = False).to(\"cuda\")\n",
    "print(model)\n",
    "# define output directory path\n",
    "current_date = datetime.datetime.now()\n",
    "datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}\"\n",
    "output_dir = f\"/vsphhome/xwx/Geneformer/models/{datestamp}_geneformer_DepressionClassifier_L{max_input_size}_B{geneformer_batch_size}_LR{max_lr}_LS{lr_schedule_fn}_WU{warmup_steps}_E{epochs}_O{optimizer}_F{freeze_layers}/\"\n",
    "\n",
    "# ensure not overwriting previously saved model\n",
    "saved_model_test = os.path.join(output_dir, f\"pytorch_model.bin\")\n",
    "if os.path.isfile(saved_model_test) == True:\n",
    "    raise Exception(\"Model already saved to this directory.\")\n",
    "\n",
    "# make output directory\n",
    "subprocess.call(f'mkdir {output_dir}', shell=True)\n",
    "\n",
    "# set training arguments\n",
    "training_args = {\n",
    "    \"learning_rate\": max_lr,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"logging_steps\": logging_steps,\n",
    "    \"group_by_length\": True,\n",
    "    \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": lr_schedule_fn,\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"per_device_train_batch_size\": geneformer_batch_size,\n",
    "    \"per_device_eval_batch_size\": geneformer_batch_size,\n",
    "    \"num_train_epochs\": epochs,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"output_dir\": output_dir,\n",
    "}\n",
    "\n",
    "training_args_init = TrainingArguments(**training_args)\n",
    "\n",
    "# create the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_init,\n",
    "    data_collator=DataCollatorForCellClassification(),\n",
    "    train_dataset=organ_trainset,\n",
    "    eval_dataset=organ_evalset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "# train the cell type classifier\n",
    "trainer.train()\n",
    "predictions = trainer.predict(organ_evalset)\n",
    "with open(f\"{output_dir}predictions.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(predictions, fp)\n",
    "trainer.save_metrics(\"eval\",predictions.metrics)\n",
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89a11ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 0]\n",
      "(15777, 2) (15777,)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.label_ids)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9984a23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.77346176, -0.77803445],\n",
       "       [-1.2236983 ,  0.8859356 ],\n",
       "       [ 1.440623  , -1.3611727 ],\n",
       "       ...,\n",
       "       [-1.7334038 ,  1.273731  ],\n",
       "       [-2.879622  ,  2.3565166 ],\n",
       "       [ 1.3992474 , -1.329712  ]], dtype=float32), label_ids=array([1, 1, 0, ..., 1, 1, 0]), metrics={'test_loss': 0.4160965383052826, 'test_accuracy': 0.8094060974836788, 'test_macro_f1': 0.8083044936447897, 'test_runtime': 48.8708, 'test_samples_per_second': 322.831, 'test_steps_per_second': 8.983})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba1599a1f7e611c14c87ccff6793920aa63510b01fc0e229d6dd014149b8829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
