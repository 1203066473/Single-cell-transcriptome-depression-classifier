{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a91bca46-c056-4784-8c6c-b0f5d3f33496",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizing .loom or .h5ad single cell RNA-seq data to rank value encoding .dataset format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "350e6252-b783-494b-9767-f087eb868a15",
   "metadata": {},
   "source": [
    "#### Input data is a directory with .loom or .h5ad files containing raw counts from single cell RNAseq data, including all genes detected in the transcriptome without feature selection. The input file type is specified by the argument file_format in the tokenize_data function.\n",
    "\n",
    "#### The discussion below references the .loom file format, but the analagous labels are required for .h5ad files, just that they will be column instead of row attributes and vice versa due to the transposed format of the two file types.\n",
    "\n",
    "#### Genes should be labeled with Ensembl IDs (loom row attribute \"ensembl_id\"), which provide a unique identifer for conversion to tokens. Other forms of gene annotations (e.g. gene names) can be converted to Ensembl IDs via Ensembl Biomart. Cells should be labeled with the total read count in the cell (loom column attribute \"n_counts\") to be used for normalization.\n",
    "\n",
    "#### No cell metadata is required, but custom cell attributes may be passed onto the tokenized dataset by providing a dictionary of custom attributes to be added, which is formatted as loom_col_attr_name : desired_dataset_col_attr_name. For example, if the original .loom dataset has column attributes \"cell_type\" and \"organ_major\" and one would like to retain these attributes as labels in the tokenized dataset with the new names \"cell_type\" and \"organ\", respectively, the following custom attribute dictionary should be provided: {\"cell_type\": \"cell_type\", \"organ_major\": \"organ\"}. \n",
    "\n",
    "#### Additionally, if the original .loom file contains a cell column attribute called \"filter_pass\", this column will be used as a binary indicator of whether to include these cells in the tokenized data. All cells with \"1\" in this attribute will be tokenized, whereas the others will be excluded. One may use this column to indicate QC filtering or other criteria for selection for inclusion in the final tokenized dataset.\n",
    "\n",
    "#### If one's data is in other formats besides .loom or .h5ad, one can use the relevant tools (such as Anndata tools) to convert the file to a .loom or .h5ad format prior to running the transcriptome tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080fdd9c-0c48-4d5d-a254-52b6c53cdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneformer import TranscriptomeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37205758-aa52-4443-a383-0638519ee8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No .loom files found in directory loom_data_directory.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tk \u001b[39m=\u001b[39m TranscriptomeTokenizer({\u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morgan_major\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39morgan\u001b[39m\u001b[39m\"\u001b[39m}, nproc\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tk\u001b[39m.\u001b[39mtokenize_data(\u001b[39m\"\u001b[39m\u001b[39mloom_data_directory\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39moutput_directory\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39moutput_prefix\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                  file_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloom\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/tokenizer.py:129\u001b[0m, in \u001b[0;36mTranscriptomeTokenizer.tokenize_data\u001b[0;34m(self, data_directory, output_directory, output_prefix, file_format, use_generator)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize_data\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    107\u001b[0m     data_directory: Path \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     use_generator: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    112\u001b[0m ):\n\u001b[1;32m    113\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    Tokenize .loom files in loom_data_directory and save as tokenized .dataset in output_directory.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m        Whether to use generator or dict for tokenization.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     tokenized_cells, cell_metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize_files(\n\u001b[1;32m    130\u001b[0m         Path(data_directory), file_format\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m     tokenized_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_dataset(tokenized_cells, cell_metadata, use_generator\u001b[39m=\u001b[39muse_generator)\n\u001b[1;32m    134\u001b[0m     output_path \u001b[39m=\u001b[39m (Path(output_directory) \u001b[39m/\u001b[39m output_prefix)\u001b[39m.\u001b[39mwith_suffix(\u001b[39m\"\u001b[39m\u001b[39m.dataset\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geneenv/lib/python3.11/site-packages/geneformer/tokenizer.py:165\u001b[0m, in \u001b[0;36mTranscriptomeTokenizer.tokenize_files\u001b[0;34m(self, data_directory, file_format)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m file_found \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    163\u001b[0m     logger\u001b[39m.\u001b[39merror(\n\u001b[1;32m    164\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo .\u001b[39m\u001b[39m{\u001b[39;00mfile_format\u001b[39m}\u001b[39;00m\u001b[39m files found in directory \u001b[39m\u001b[39m{\u001b[39;00mdata_directory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_cells, cell_metadata\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "from geneformer import TranscriptomeTokenizer\n",
    "tk = TranscriptomeTokenizer({\"label\": \"label\"}, nproc=4)\n",
    "tk.tokenize_data(\"/vsphhome/xwx/Geneformer/RNA_data/MMD_snRNA_loom\",#loom data directory\n",
    "                \"/vsphhome/xwx/Geneformer/token_data/\", #output directory\n",
    "                    output_prefix=\"MMD_snRNA\")#output prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
